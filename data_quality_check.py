#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í•œêµ­ ì‹œì¥ ë°ì´í„° í’ˆì§ˆ ì¢…í•© ì ê²€
- Universe ì»¤ë²„ë¦¬ì§€
- ë°ì´í„° ì™„ì „ì„±
- ì‹œê³„ì—´ ì—°ì†ì„±
- ìƒì¥íì§€/ê´€ë¦¬ì¢…ëª© ì²˜ë¦¬
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from collections import defaultdict
import pykrx.stock as stock

from cache_manager import load_enriched
try:
    from config import START, END
except:
    START = "2020-01-01"
    END = None

print("=" * 80)
print("ğŸ“Š í•œêµ­ ì‹œì¥ ë°ì´í„° í’ˆì§ˆ ì¢…í•© ì ê²€")
print("=" * 80)

# =============================================================================
# 1. Universe ë²”ìœ„ í™•ì¸
# =============================================================================
print("\n1ï¸âƒ£ Universe ë²”ìœ„ í™•ì¸")
print("-" * 80)

try:
    # í˜„ì¬ ìƒì¥ ì¢…ëª© ìˆ˜
    kospi_tickers = stock.get_market_ticker_list(market="KOSPI")
    kosdaq_tickers = stock.get_market_ticker_list(market="KOSDAQ")
    konex_tickers = stock.get_market_ticker_list(market="KONEX")
    
    print(f"âœ… KOSPI ì¢…ëª©: {len(kospi_tickers):,}ê°œ")
    print(f"âœ… KOSDAQ ì¢…ëª©: {len(kosdaq_tickers):,}ê°œ")
    print(f"âœ… KONEX ì¢…ëª©: {len(konex_tickers):,}ê°œ")
    print(f"   ì´ê³„: {len(kospi_tickers) + len(kosdaq_tickers) + len(konex_tickers):,}ê°œ")
    
    all_tickers = set(kospi_tickers + kosdaq_tickers + konex_tickers)
    
except Exception as e:
    print(f"âŒ Universe ì¡°íšŒ ì‹¤íŒ¨: {e}")
    all_tickers = set()

# =============================================================================
# 2. ìºì‹œëœ ë°ì´í„° í™•ì¸
# =============================================================================
print("\n2ï¸âƒ£ ìºì‹œëœ ë°ì´í„° í™•ì¸")
print("-" * 80)

import glob
import os

# ì˜¬ë°”ë¥¸ ê²½ë¡œ ì‚¬ìš©
enriched_dir = "data/enriched"
ohlcv_dir = "data/ohlcv"

enriched_files = glob.glob(f"{enriched_dir}/*_*.parquet")

print(f"ìºì‹œëœ enriched íŒŒì¼: {len(enriched_files):,}ê°œ")

# íŒŒì¼ë³„ ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œ
cached_tickers = set()
date_ranges = {}
file_sizes = []

for f in enriched_files:
    basename = os.path.basename(f)
    parts = basename.replace(".parquet", "").split("_")
    if len(parts) >= 3:
        ticker = parts[0]
        cached_tickers.add(ticker)
        
        # íŒŒì¼ í¬ê¸°
        size_mb = os.path.getsize(f) / (1024 * 1024)
        file_sizes.append(size_mb)
        
        # ë‚ ì§œ ë²”ìœ„ (íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ)
        if len(parts) == 3:
            start_date = parts[1]
            end_date = parts[2]
            date_ranges[ticker] = (start_date, end_date)

print(f"ìºì‹œëœ ì¢…ëª©: {len(cached_tickers):,}ê°œ")
print(f"í‰ê·  íŒŒì¼ í¬ê¸°: {np.mean(file_sizes):.2f} MB")
print(f"ì´ ìºì‹œ í¬ê¸°: {np.sum(file_sizes):.2f} MB")

# Universeì™€ ìºì‹œ ë¹„êµ
if all_tickers:
    cached_ratio = len(cached_tickers) / len(all_tickers) * 100
    print(f"\nìºì‹œ ì»¤ë²„ë¦¬ì§€: {cached_ratio:.1f}% ({len(cached_tickers)}/{len(all_tickers)})")
    
    missing = all_tickers - cached_tickers
    if len(missing) > 0:
        print(f"âš ï¸  ìºì‹œ ëˆ„ë½ ì¢…ëª©: {len(missing):,}ê°œ")
        print(f"   ì˜ˆì‹œ: {list(missing)[:10]}")

# =============================================================================
# 3. ë°ì´í„° ì™„ì „ì„± ì ê²€ (ìƒ˜í”Œë§)
# =============================================================================
print("\n3ï¸âƒ£ ë°ì´í„° ì™„ì „ì„± ì ê²€ (ìƒ˜í”Œ 100ê°œ)")
print("-" * 80)

sample_tickers = list(cached_tickers)[:100] if len(cached_tickers) > 100 else list(cached_tickers)

completeness_report = {
    "total": 0,
    "has_ohlcv": 0,
    "has_volume": 0,
    "has_indicators": 0,
    "missing_data": 0,
    "date_gaps": 0,
    "zero_volume_days": [],
}

expected_columns = ["open", "high", "low", "close", "volume"]
indicator_columns = ["rsi14", "ma20", "ma60"]

for ticker in sample_tickers:
    completeness_report["total"] += 1
    
    df = load_enriched(ticker, START, END)
    
    if df is None or len(df) == 0:
        completeness_report["missing_data"] += 1
        continue
    
    # OHLCV ì¡´ì¬ ì—¬ë¶€
    if all(col in df.columns for col in expected_columns):
        completeness_report["has_ohlcv"] += 1
    
    # Volume ë°ì´í„° í’ˆì§ˆ
    if "volume" in df.columns:
        vol_series = df["volume"]
        if vol_series.notna().sum() > 0:
            completeness_report["has_volume"] += 1
            
            # ê±°ë˜ëŸ‰ 0ì¸ ë‚  ë¹„ìœ¨
            zero_vol_ratio = (vol_series == 0).sum() / len(vol_series)
            if zero_vol_ratio > 0.1:  # 10% ì´ìƒ
                completeness_report["zero_volume_days"].append((ticker, zero_vol_ratio))
    
    # ì§€í‘œ ì¡´ì¬ ì—¬ë¶€
    if any(col in df.columns for col in indicator_columns):
        completeness_report["has_indicators"] += 1
    
    # ë‚ ì§œ ì—°ì†ì„± (ê±°ë˜ì¼ ê¸°ì¤€)
    if len(df) > 1:
        date_diffs = df.index.to_series().diff().dt.days
        # ê±°ë˜ì¼ ê¸°ì¤€ 5ì¼ ì´ìƒ ê°­ì€ ë¹„ì •ìƒ
        long_gaps = (date_diffs > 5).sum()
        if long_gaps > 0:
            completeness_report["date_gaps"] += 1

print(f"ì´ ìƒ˜í”Œ: {completeness_report['total']:,}ê°œ")
print(f"OHLCV ì™„ì „: {completeness_report['has_ohlcv']:,}ê°œ ({completeness_report['has_ohlcv']/completeness_report['total']*100:.1f}%)")
print(f"Volume ë°ì´í„°: {completeness_report['has_volume']:,}ê°œ ({completeness_report['has_volume']/completeness_report['total']*100:.1f}%)")
print(f"ì§€í‘œ ê³„ì‚°ë¨: {completeness_report['has_indicators']:,}ê°œ ({completeness_report['has_indicators']/completeness_report['total']*100:.1f}%)")
print(f"ë°ì´í„° ëˆ„ë½: {completeness_report['missing_data']:,}ê°œ")
print(f"ë‚ ì§œ ê°­ ë°œê²¬: {completeness_report['date_gaps']:,}ê°œ")

if len(completeness_report["zero_volume_days"]) > 0:
    print(f"\nâš ï¸  ê±°ë˜ëŸ‰ 0 ë¹„ìœ¨ ë†’ì€ ì¢…ëª© (>10%): {len(completeness_report['zero_volume_days'])}ê°œ")
    for ticker, ratio in completeness_report["zero_volume_days"][:5]:
        print(f"   {ticker}: {ratio*100:.1f}%")

# =============================================================================
# 4. ì‹œê³„ì—´ ë²”ìœ„ ì ê²€
# =============================================================================
print("\n4ï¸âƒ£ ì‹œê³„ì—´ ë²”ìœ„ ì ê²€")
print("-" * 80)

time_ranges = []
for ticker in sample_tickers[:50]:
    df = load_enriched(ticker, START, END)
    if df is not None and len(df) > 0:
        time_ranges.append({
            "ticker": ticker,
            "start": df.index[0],
            "end": df.index[-1],
            "days": len(df),
        })

if len(time_ranges) > 0:
    df_ranges = pd.DataFrame(time_ranges)
    
    print(f"ìµœì†Œ ì‹œì‘ì¼: {df_ranges['start'].min().date()}")
    print(f"ìµœëŒ€ ì¢…ë£Œì¼: {df_ranges['end'].max().date()}")
    print(f"í‰ê·  ë°ì´í„° ì¼ìˆ˜: {df_ranges['days'].mean():.0f}ì¼")
    print(f"ìµœì†Œ ë°ì´í„° ì¼ìˆ˜: {df_ranges['days'].min():.0f}ì¼")
    print(f"ìµœëŒ€ ë°ì´í„° ì¼ìˆ˜: {df_ranges['days'].max():.0f}ì¼")
    
    # ìµœê·¼ ë°ì´í„° ì‹ ì„ ë„
    today = pd.Timestamp.now()
    latest_end = df_ranges['end'].max()
    days_old = (today - latest_end).days
    
    print(f"\në°ì´í„° ì‹ ì„ ë„:")
    print(f"  ìµœê·¼ ë°ì´í„°: {latest_end.date()}")
    print(f"  ì˜¤ëŠ˜ ê¸°ì¤€: {days_old}ì¼ ì „")
    
    if days_old > 3:
        print(f"  âš ï¸  ë°ì´í„°ê°€ {days_old}ì¼ ì˜¤ë˜ë¨. ì—…ë°ì´íŠ¸ í•„ìš”!")

# =============================================================================
# 5. ì‹œê°€ì´ì•¡ ë°ì´í„° í™•ì¸
# =============================================================================
print("\n5ï¸âƒ£ ì‹œê°€ì´ì•¡ ë°ì´í„° í™•ì¸")
print("-" * 80)

market_cap_count = 0
for ticker in sample_tickers[:50]:
    df = load_enriched(ticker, START, END)
    if df is not None and "market_cap" in df.columns:
        if df["market_cap"].notna().sum() > 0:
            market_cap_count += 1

print(f"ì‹œê°€ì´ì•¡ ë°ì´í„° ë³´ìœ : {market_cap_count}/50 ({market_cap_count/50*100:.1f}%)")

if market_cap_count == 0:
    print("âš ï¸  ì‹œê°€ì´ì•¡ ë°ì´í„° ì—†ìŒ - Universe í•„í„°ë§ ì œí•œë¨!")

# =============================================================================
# 6. ìƒì¥íì§€/ê´€ë¦¬ì¢…ëª© ì²˜ë¦¬ í™•ì¸
# =============================================================================
print("\n6ï¸âƒ£ ìƒì¥íì§€/ê´€ë¦¬ì¢…ëª© ì²˜ë¦¬")
print("-" * 80)

# ìºì‹œì—ëŠ” ìˆì§€ë§Œ í˜„ì¬ ìƒì¥ ì¢…ëª© ëª©ë¡ì— ì—†ëŠ” ì¢…ëª©
if all_tickers:
    delisted = cached_tickers - all_tickers
    print(f"ìƒì¥íì§€/ì œì™¸ ì¢…ëª© (ìºì‹œì—ë§Œ ì¡´ì¬): {len(delisted):,}ê°œ")
    if len(delisted) > 0:
        print(f"  ì˜ˆì‹œ: {list(delisted)[:10]}")
        print(f"  âœ… ê³¼ê±° ë°±í…ŒìŠ¤íŠ¸ì— ë°˜ì˜ë¨ (Survivorship Bias ìµœì†Œí™”)")

# =============================================================================
# 7. ì¢…í•© ì ìˆ˜
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ“Š ì¢…í•© í‰ê°€")
print("=" * 80)

scores = []

# Universe ì»¤ë²„ë¦¬ì§€
if all_tickers and len(cached_tickers) > 0:
    coverage_score = min(100, cached_ratio)
    scores.append(("Universe ì»¤ë²„ë¦¬ì§€", coverage_score))
else:
    scores.append(("Universe ì»¤ë²„ë¦¬ì§€", 0))

# ë°ì´í„° ì™„ì „ì„±
if completeness_report["total"] > 0:
    completeness_score = (completeness_report["has_ohlcv"] / completeness_report["total"]) * 100
    scores.append(("ë°ì´í„° ì™„ì „ì„±", completeness_score))

# ì§€í‘œ ê³„ì‚°
if completeness_report["total"] > 0:
    indicator_score = (completeness_report["has_indicators"] / completeness_report["total"]) * 100
    scores.append(("ì§€í‘œ ê³„ì‚°", indicator_score))

# ì‹œê³„ì—´ ì—°ì†ì„±
if completeness_report["total"] > 0:
    continuity_score = ((completeness_report["total"] - completeness_report["date_gaps"]) / completeness_report["total"]) * 100
    scores.append(("ì‹œê³„ì—´ ì—°ì†ì„±", continuity_score))

# ë°ì´í„° ì‹ ì„ ë„
if 'days_old' in locals():
    if days_old <= 1:
        freshness_score = 100
    elif days_old <= 3:
        freshness_score = 80
    elif days_old <= 7:
        freshness_score = 60
    else:
        freshness_score = 40
    scores.append(("ë°ì´í„° ì‹ ì„ ë„", freshness_score))

print("\nê°œë³„ ì ìˆ˜:")
for name, score in scores:
    status = "âœ…" if score >= 80 else "âš ï¸" if score >= 60 else "âŒ"
    print(f"  {status} {name}: {score:.1f}/100")

if len(scores) > 0:
    overall_score = np.mean([s[1] for s in scores])
    print(f"\nì¢…í•© ì ìˆ˜: {overall_score:.1f}/100")
    
    if overall_score >= 80:
        print("âœ… ë°ì´í„° í’ˆì§ˆ: ìš°ìˆ˜ - ë°±í…ŒìŠ¤íŠ¸ ì‹ ë¢° ê°€ëŠ¥")
    elif overall_score >= 60:
        print("âš ï¸  ë°ì´í„° í’ˆì§ˆ: ì–‘í˜¸ - ì£¼ì˜í•˜ì—¬ ì‚¬ìš©")
    else:
        print("âŒ ë°ì´í„° í’ˆì§ˆ: ë¶ˆëŸ‰ - ë°ì´í„° ì—…ë°ì´íŠ¸ í•„ìš”")

# =============================================================================
# 8. ê¶Œì¥ ì‚¬í•­
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ’¡ ê¶Œì¥ ì‚¬í•­")
print("=" * 80)

recommendations = []

if all_tickers and cached_ratio < 90:
    recommendations.append("â€¢ Universe ì»¤ë²„ë¦¬ì§€ í–¥ìƒì„ ìœ„í•´ ì „ì²´ ë°ì´í„° ì¬ìˆ˜ì§‘ ê¶Œì¥")

if completeness_report["missing_data"] > 10:
    recommendations.append("â€¢ ë°ì´í„° ëˆ„ë½ ì¢…ëª© ì¬ìˆ˜ì§‘ í•„ìš”")

if completeness_report["date_gaps"] > 5:
    recommendations.append("â€¢ ì‹œê³„ì—´ ê°­ì´ ìˆëŠ” ì¢…ëª©ë“¤ ë°ì´í„° ë³´ì™„ í•„ìš”")

if 'days_old' in locals() and days_old > 3:
    recommendations.append(f"â€¢ ë°ì´í„°ê°€ {days_old}ì¼ ì˜¤ë˜ë¨ - ì¦‰ì‹œ ì—…ë°ì´íŠ¸ í•„ìš”")

if market_cap_count < 40:
    recommendations.append("â€¢ ì‹œê°€ì´ì•¡ ë°ì´í„° ìˆ˜ì§‘ ë¡œì§ ì¶”ê°€ ê¶Œì¥ (Universe í•„í„°ë§ ê°œì„ )")

if len(completeness_report["zero_volume_days"]) > 10:
    recommendations.append("â€¢ ê±°ë˜ëŸ‰ 0 ì¢…ëª© ë§ìŒ - ìƒì¥íì§€ ë˜ëŠ” ë°ì´í„° ì˜¤ë¥˜ í™•ì¸")

if len(recommendations) > 0:
    for rec in recommendations:
        print(rec)
else:
    print("âœ… í˜„ì¬ ë°ì´í„° í’ˆì§ˆ ìš°ìˆ˜ - ì¶”ê°€ ì¡°ì¹˜ ë¶ˆí•„ìš”")

print("\n" + "=" * 80)
print("ì ê²€ ì™„ë£Œ!")
print("=" * 80)

