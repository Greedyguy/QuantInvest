import pandas as pd, numpy as np, re
pd.set_option('future.no_silent_downcasting', True)
from datetime import datetime, date, timedelta
from pykrx import stock
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

from config import DATA_STALE_TOLERANCE_BDAYS

DATA_DIR = os.path.join(os.path.dirname(__file__), "data", "ohlcv")
os.makedirs(DATA_DIR, exist_ok=True)

def _bizdays(start, end):
    return pd.bdate_range(start, end, freq="C")


def _business_day_gap(old: pd.Timestamp, new: pd.Timestamp) -> int:
    if old is None or pd.isna(old) or new is None or pd.isna(new):
        return DATA_STALE_TOLERANCE_BDAYS + 1
    if new <= old:
        return 0
    try:
        old_day = np.datetime64(old.date())
        new_day = np.datetime64(new.date())
        if new_day <= old_day:
            return 0
        return int(np.busday_count(old_day, new_day))
    except Exception:
        return max(int((new - old).days), 0)


def _is_cache_stale(cache_end: pd.Timestamp, req_end: pd.Timestamp) -> bool:
    if cache_end is None or pd.isna(cache_end):
        return True
    if req_end is None or pd.isna(req_end):
        return True
    if cache_end >= req_end:
        return False
    return _business_day_gap(cache_end, req_end) > DATA_STALE_TOLERANCE_BDAYS


def _download_ohlcv_block(
    ticker: str,
    start: str,
    end: str,
    include_market_cap: bool = True,
    min_rows: int = 120,
) -> pd.DataFrame:
    try:
        raw = stock.get_market_ohlcv_by_date(start, end, ticker)
    except Exception as e:
        print(f"[ERR] {ticker}: pykrx-call -> {type(e).__name__}: {e}")
        return pd.DataFrame()

    try:
        df = _normalize_df(raw, min_rows=min_rows)
    except Exception as e:
        print(f"[ERR] {ticker}: normalize -> {type(e).__name__}: {e}")
        return pd.DataFrame()

    if df.empty:
        return pd.DataFrame()

    if include_market_cap:
        try:
            df_cap = get_market_cap(ticker, start, end)
            if not df_cap.empty:
                df = df.join(df_cap, how="left")
        except Exception as e:
            print(f"[WARN] {ticker}: market_cap -> {type(e).__name__}: {e}")
    return df

def get_ohlcv(ticker, start, end):
    df = stock.get_market_ohlcv_by_date(start, end, ticker)

    # ì»¬ëŸ¼ í‘œì¤€í™”: ê¸°ë³¸ ê¸°ëŒ€ ì»¬ëŸ¼
    rename_map = {"ì‹œê°€":"open","ê³ ê°€":"high","ì €ê°€":"low","ì¢…ê°€":"close",
                  "ê±°ë˜ëŸ‰":"volume","ê±°ë˜ëŒ€ê¸ˆ":"value"}
    # í˜¹ì‹œ MultiIndex/ì˜ë¬¸ í˜¼ìš© ë°©ì§€
    df.columns = [str(c) for c in df.columns]
    df = df.rename(columns=rename_map)

    # í•„ìˆ˜ ì»¬ëŸ¼ ì±„ìš°ê¸°
    for c_old, c_new in rename_map.items():
        if c_new not in df.columns and c_old in df.columns:
            df[c_new] = df[c_old]

    # ê±°ë˜ëŒ€ê¸ˆ ì—†ìœ¼ë©´ ê³„ì‚°ì‹ìœ¼ë¡œ ëŒ€ì²´
    if "value" not in df.columns:
        if ("close" in df.columns) and ("volume" in df.columns):
            df["value"] = df["close"].astype("float64") * df["volume"].astype("float64")
        else:
            # ì •ë§ë¡œ ë§Œë“¤ ìˆ˜ ì—†ìœ¼ë©´ ë¹ˆ í”„ë ˆì„ ë°˜í™˜
            return pd.DataFrame()

    # ìˆ«ìí˜• ê°•ì œ
    for c in ["open","high","low","close","volume","value"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    # ê²°ì¸¡/ë¹„ì •ìƒ ì œê±°
    df = df.dropna(subset=["open","high","low","close","volume","value"])
    # ìµœì†Œ ê¸¸ì´ ë³´ì¥ (ë‚˜ì¤‘ computeì—ì„œ ê°€ì •)
    if len(df) < 120:
        return pd.DataFrame()

    return df[["open","high","low","close","volume","value"]]

REQ_COLS = ["open","high","low","close","volume","value"]  # í•„ìˆ˜ ì»¬ëŸ¼

def _is_bad_column(col):
    """ì»¬ëŸ¼ ê°ì²´ê°€ None/ìŠ¤ì¹¼ë¼/ê¸¸ì´0/ì „ë¶€ NaN ë“±ì¸ ê²½ìš° True"""
    if col is None:
        return True
    # ìŠ¤ì¹¼ë¼(ìˆ«ì/ë¬¸ì)ë©´ DF ì»¬ëŸ¼ì´ ì•„ë‹˜
    if np.isscalar(col):
        return True
    try:
        # ê¸¸ì´ ì—†ëŠ” ì´ìƒ ê°ì²´
        if len(col) == 0:
            return True
    except Exception:
        return True
    # ì „ë¶€ NaN
    try:
        if pd.isna(col).all():
            return True
    except Exception:
        pass
    return False

def _normalize_df(raw, min_rows=120):
    """pykrx ë°˜í™˜ì„ í‘œì¤€ DFë¡œ ì •ê·œí™”. ì‹¤íŒ¨ì‹œ ë¹ˆ DF"""
    if raw is None or not isinstance(raw, pd.DataFrame) or raw.empty:
        return pd.DataFrame()

    # ì»¬ëŸ¼ëª… í‘œì¤€í™”
    raw.columns = [str(c) for c in raw.columns]
    rename_map = {"ì‹œê°€":"open","ê³ ê°€":"high","ì €ê°€":"low","ì¢…ê°€":"close",
                  "ê±°ë˜ëŸ‰":"volume","ê±°ë˜ëŒ€ê¸ˆ":"value"}
    df = raw.rename(columns=rename_map).copy()

    # ê±°ë˜ëŒ€ê¸ˆ ë¯¸ì œê³µì‹œ ê³„ì‚°
    if "value" not in df.columns and {"close","volume"}.issubset(df.columns):
        df["value"] = df["close"] * df["volume"]

    # í•„ìˆ˜ ì»¬ëŸ¼ì´ í•˜ë‚˜ë¼ë„ ì—†ê±°ë‚˜ "ì´ìƒ ì»¬ëŸ¼"ì´ë©´ ë²„ë¦¼
    for c in REQ_COLS:
        if c not in df.columns:
            return pd.DataFrame()
        if _is_bad_column(df[c]):
            return pd.DataFrame()

    # ìˆ«ìí˜• ê°•ì œ ë³€í™˜ (ì—¬ê¸°ì„œë„ ì˜ˆì™¸ì‹œ ë²„ë¦¼)
    for c in REQ_COLS:
        try:
            df[c] = pd.to_numeric(df[c], errors="coerce")
        except Exception:
            return pd.DataFrame()

    # ê²°ì¸¡ ì œê±° + ìµœì†Œ ê¸¸ì´
    df = df.dropna(subset=REQ_COLS)
    if len(df) < min_rows:
        return pd.DataFrame()

    return df[REQ_COLS]

def get_market_cap(ticker, start, end):
    """
    ì‹œê°€ì´ì•¡ ë°ì´í„° ìˆ˜ì§‘
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        start: ì‹œì‘ì¼ (YYYY-MM-DD)
        end: ì¢…ë£Œì¼ (YYYY-MM-DD)
    
    Returns:
        DataFrame with market_cap column
    """
    try:
        # pykrxì—ì„œ ì‹œê°€ì´ì•¡ ì¡°íšŒ
        df_cap = stock.get_market_cap_by_date(start, end, ticker)
        
        if df_cap is None or df_cap.empty:
            return pd.DataFrame()
        
        # ì»¬ëŸ¼ëª… ì •ê·œí™”
        df_cap.columns = [str(c) for c in df_cap.columns]
        rename_map = {
            "ì‹œê°€ì´ì•¡": "market_cap",
            "ê±°ë˜ëŸ‰": "volume_cap",  # ì¤‘ë³µ ë°©ì§€
            "ê±°ë˜ëŒ€ê¸ˆ": "value_cap",
            "ìƒì¥ì£¼ì‹ìˆ˜": "shares",
        }
        df_cap = df_cap.rename(columns=rename_map)
        
        # ì‹œê°€ì´ì•¡ë§Œ ì¶”ì¶œ
        if "market_cap" in df_cap.columns:
            df_result = pd.DataFrame(index=df_cap.index)
            df_result["market_cap"] = pd.to_numeric(df_cap["market_cap"], errors="coerce")
            return df_result
        
        return pd.DataFrame()
    
    except Exception as e:
        # pykrx API ì˜¤ë¥˜ ì‹œ ì¡°ìš©íˆ ë¬´ì‹œ (ì‹œê°€ì´ì•¡ ì—†ì´ ì§„í–‰)
        return pd.DataFrame()


def get_ohlcv_one(ticker, start, end, include_market_cap=True):
    """
    ì ˆëŒ€ Noneì„ ë°˜í™˜í•˜ì§€ ì•ŠëŠ” ì•ˆì „ ë²„ì „
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        start: ì‹œì‘ì¼
        end: ì¢…ë£Œì¼
        include_market_cap: ì‹œê°€ì´ì•¡ ë°ì´í„° í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸: True)
    """
    fp = os.path.join(DATA_DIR, f"{ticker}.parquet")

    # 1) ìºì‹œ ìš°ì„ 
    if os.path.exists(fp):
        try:
            df = pd.read_parquet(fp)
            if isinstance(df, pd.DataFrame) and not df.empty:
                # ìºì‹œê°€ ì´ìƒí•˜ë©´ ì—¬ê¸°ì„œë„ ê²€ì‚¬
                df = _normalize_df(df, min_rows=1)
                if not df.empty:
                    full_df = df
                    cached_end = full_df.index.max()
                    req_end = pd.to_datetime(end)
                    if _is_cache_stale(cached_end, req_end):
                        fetch_start_ts = cached_end + pd.Timedelta(days=1)
                        fetch_start = fetch_start_ts.strftime("%Y-%m-%d")
                        print(f"[INFO] {ticker}: cached OHLCV stale (last={cached_end.date()}, req={req_end.date()}) â†’ incremental download from {fetch_start}")
                        incremental = _download_ohlcv_block(
                            ticker,
                            fetch_start,
                            end,
                            include_market_cap,
                            min_rows=1,
                        )
                        if incremental.empty:
                            # pykrxì—ì„œ ì‹ ë°ì´í„°ë¥¼ ëª» ë°›ì€ ê²½ìš° ì „ì²´ ì¬ë‹¤ìš´ë¡œë“œ ì‹œë„
                            full_df = pd.DataFrame()
                        else:
                            full_df = pd.concat([full_df, incremental])
                            full_df = full_df[~full_df.index.duplicated(keep='last')]
                            full_df = full_df.sort_index()
                            try:
                                full_df.to_parquet(fp, index=True)
                            except Exception as e:
                                print(f"[WARN] {ticker}: parquet-save(update) -> {type(e).__name__}: {e}")
                    else:
                        if include_market_cap and "market_cap" not in full_df.columns:
                            df_cap = get_market_cap(ticker, start, end)
                            if not df_cap.empty:
                                full_df = full_df.join(df_cap, how="left")
                                try:
                                    full_df.to_parquet(fp, index=True)
                                except Exception as e:
                                    print(f"[WARN] {ticker}: parquet-save(cap) -> {type(e).__name__}: {e}")
                    if full_df is not None and not full_df.empty:
                        req_start = pd.to_datetime(start)
                        trimmed = full_df[(full_df.index >= req_start) & (full_df.index <= req_end)]
                        if not trimmed.empty:
                            return trimmed
        except Exception:
            pass  # ì†ìƒì‹œ ì¬ë‹¤ìš´

    # 2) ë‹¤ìš´ë¡œë“œ
    df = _download_ohlcv_block(ticker, start, end, include_market_cap)

    # 5) ìºì‹œ ì €ì¥ (ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ)
    if not df.empty:
        try:
            df.to_parquet(fp, index=True)
        except Exception as e:
            print(f"[WARN] {ticker}: parquet-save -> {type(e).__name__}: {e}")

    return df if not df.empty else pd.DataFrame()

from pykrx import stock

def get_index_close(market, start, end):
    """
    KOSPI/KOSDAQ ì§€ìˆ˜ ì¢…ê°€ë¥¼ yfinanceë¡œ ê°€ì ¸ì˜¤ëŠ” ë²„ì „
    market: "KOSPI" or "KOSDAQ"
    start, end: "YYYY-MM-DD" ë˜ëŠ” datetime-like
    """
    import yfinance as yf
    import pandas as pd

    m = str(market).upper().strip()
    if m == "KOSPI":
        symbol = "^KS11"
    elif m == "KOSDAQ":
        symbol = "^KQ11"
    else:
        print(f"[WARN] get_index_close: ì§€ì›í•˜ì§€ ì•ŠëŠ” market={market}")
        return pd.DataFrame()

    start_dt = pd.to_datetime(start)
    end_dt   = pd.to_datetime(end)

    try:
        # auto_adjust=False ë¡œ ëª…ì‹œ + progress bar ë„ê¸°
        df_raw = yf.download(
            symbol,
            start=start_dt,
            end=end_dt,
            auto_adjust=False,
            progress=False,
        )
    except Exception as e:
        print(f"[ERROR] {market}({symbol}) yfinance ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {type(e).__name__}: {e}")
        return pd.DataFrame()

    if df_raw is None or df_raw.empty:
        print(f"[WARN] {market}({symbol}) yfinance: ë¹ˆ ë°ì´í„°")
        return pd.DataFrame()

    # ğŸ”¹ MultiIndex(í•„ë“œ, í‹°ì»¤) / ë‹¨ì¼ì»¬ëŸ¼ ëª¨ë‘ ëŒ€ì‘
    if isinstance(df_raw.columns, pd.MultiIndex):
        # level 0 ì—ì„œ 'Close' ì°¾ê¸°
        lvl0 = [str(c).lower() for c in df_raw.columns.get_level_values(0)]
        if "close" in lvl0:
            # level 0 ì—ì„œ 'Close' slice
            close_df = df_raw.xs("Close", axis=1, level=0)
        else:
            # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ë§ˆì§€ë§‰ ë ˆë²¨0 ì‚¬ìš©
            first_field = df_raw.columns.get_level_values(0)[0]
            close_df = df_raw.xs(first_field, axis=1, level=0)

        # í‹°ì»¤ê°€ 1ê°œì¼í…Œë‹ˆ ì²« ë²ˆì§¸ ì»¬ëŸ¼ë§Œ ì‚¬ìš©
        close_series = close_df.iloc[:, 0]
    else:
        # ì¼ë°˜ DataFrame: Close ì»¬ëŸ¼ ì‚¬ìš©
        if "Close" in df_raw.columns:
            close_series = df_raw["Close"]
        elif "close" in [c.lower() for c in df_raw.columns]:
            # í˜¹ì‹œ ì†Œë¬¸ì ë“±
            c = [c for c in df_raw.columns if c.lower() == "close"][0]
            close_series = df_raw[c]
        else:
            print(f"[WARN] {market}({symbol}) Close ì»¬ëŸ¼ ì—†ìŒ: {df_raw.columns}")
            return pd.DataFrame()

    close = pd.to_numeric(close_series, errors="coerce")

    df = pd.DataFrame({"close": close})
    df = df.dropna()
    df.index = pd.to_datetime(df.index)
    df = df.sort_index()

    return df

def infer_market(ticker):
    # pykrxê°€ í‹°ì»¤ë¡œ ì‹œì¥ êµ¬ë¶„ ì œê³µX â†’ ì‹œì´í‘œì—ì„œ ìœ ì¶”
    try:
        mcap = stock.get_market_cap_by_ticker(date.today().strftime("%Y%m%d"))
        return "KOSDAQ" if ticker in mcap[mcap["ì‹œì¥êµ¬ë¶„"]=="KOSDAQ"].index else "KOSPI"
    except:
        return None

def get_universe(markets=("KOSPI","KOSDAQ"), include_etf=True, include_index_etf=True):
    """
    Universe ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ (ìºì‹œ Fallback ë²„ì „)
    
    Args:
        markets: ("KOSPI", "KOSDAQ") ë“±
        include_etf: ETF í¬í•¨ ì—¬ë¶€
        include_index_etf: ì£¼ìš” ì¸ë±ìŠ¤ ETF ê°•ì œ í¬í•¨ (KODEX 200 ë“±)
    
    Returns:
        ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
    """
    import os
    import glob
    from datetime import datetime, timedelta
    
    tickers = []
    
    # ğŸ“Œ ìµœê·¼ ê±°ë˜ì¼ ì°¾ê¸° (ì£¼ë§/ê³µíœ´ì¼ ëŒ€ì‘)
    today = datetime.now()
    last_error = None
    attempted_dates = []
    
    for days_ago in range(14):  # ìµœëŒ€ 14ì¼ ì „ê¹Œì§€ ì‹œë„
        try_date = (today - timedelta(days=days_ago)).strftime("%Y%m%d")
        attempted_dates.append(try_date)
        
        try:
            temp_tickers = []
            for m in markets:
                # ëª…ì‹œì  ë‚ ì§œ ì „ë‹¬
                ticker_list = stock.get_market_ticker_list(date=try_date, market=m)
                if ticker_list is None:
                    raise ValueError(f"pykrxê°€ Noneì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤ (market={m}, date={try_date})")
                temp_tickers += ticker_list
            
            # ì„±ê³µí•˜ë©´ ì €ì¥í•˜ê³  ì¤‘ë‹¨
            if len(temp_tickers) > 0:
                tickers = temp_tickers
                print(f"[INFO] Universe (pykrx): {len(tickers)}ê°œ ì¢…ëª© (ë‚ ì§œ: {try_date[:4]}-{try_date[4:6]}-{try_date[6:]})")
                break
            else:
                # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ ì‹œì—ë„ ì—ëŸ¬ë¡œ ê¸°ë¡
                if last_error is None:
                    last_error = ValueError(f"ëª¨ë“  ì‹œë„ ë‚ ì§œì—ì„œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ì‹œë„í•œ ë‚ ì§œ: {', '.join(attempted_dates[:3])}...)")
                
        except Exception as e:
            last_error = e
            continue  # ë‹¤ìŒ ë‚ ì§œ ì‹œë„
    
    # pykrx ì‹¤íŒ¨ ì‹œ ìºì‹œì—ì„œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
    if len(tickers) == 0:
        error_msg = str(last_error) if last_error is not None else "ì˜ˆì™¸ ì—†ì´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (14ì¼ ëª¨ë‘ ì‹œë„)"
        print(f"[WARN] pykrx Universe ì¡°íšŒ ì‹¤íŒ¨: {error_msg}")
        print(f"       â†’ ìºì‹œëœ enriched íŒŒì¼ì—ì„œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„...")
        
        enriched_dir = "data/enriched"
        if os.path.exists(enriched_dir):
            cache_files = glob.glob(f"{enriched_dir}/*.parquet")
            if len(cache_files) > 0:
                cached_tickers = list(set([
                    os.path.basename(f).split("_")[0] 
                    for f in cache_files
                ]))
                if len(cached_tickers) > 0:
                    tickers = cached_tickers
                    print(f"[INFO] Universe (ìºì‹œ): {len(tickers)}ê°œ ì¢…ëª© ì¶”ì¶œ ì™„ë£Œ")
    
    if len(tickers) == 0:
        print("[ERROR] Universeê°€ ì™„ì „íˆ ë¹„ì–´ìˆìŠµë‹ˆë‹¤ (pykrx ë° ìºì‹œ ëª¨ë‘ ì‹¤íŒ¨)")
        return []
    
    # ğŸ“Œ ì£¼ìš” ì¸ë±ìŠ¤ ETF ê°•ì œ ì¶”ê°€
    index_etfs = [
        "069500",  # KODEX 200
        "102110",  # TIGER 200
        "114800",  # KODEX ì¸ë²„ìŠ¤
        "122630",  # KODEX ë ˆë²„ë¦¬ì§€
        "229200",  # KODEX ì½”ìŠ¤ë‹¥150
        "091160",  # KODEX ë°˜ë„ì²´
        "091180",  # TIGER ì€í–‰
        "152100",  # ARIRANG 200
    ]
    
    if include_index_etf:
        for etf_code in index_etfs:
            if etf_code not in tickers:
                tickers.append(etf_code)
        print(f"[INFO] ì£¼ìš” ì¸ë±ìŠ¤ ETF {len(index_etfs)}ê°œ ì¶”ê°€ë¨")
    
    # ì¢…ëª©ëª… ì¡°íšŒ ë° í•„í„°ë§
    names = {}
    for t in tickers:
        try:
            name_result = stock.get_market_ticker_name(t)
            # DataFrameì´ë‚˜ Seriesì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
            if isinstance(name_result, (pd.DataFrame, pd.Series)):
                names[t] = str(name_result.iloc[0] if hasattr(name_result, 'iloc') else name_result)
            else:
                names[t] = str(name_result) if name_result is not None else ""
        except:
            names[t] = ""
    
    def ok(t):
        n = names.get(t, "")
        # ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
        if not isinstance(n, str):
            n = str(n)
        
        # ì£¼ìš” ì¸ë±ìŠ¤ ETFëŠ” í•­ìƒ í—ˆìš©
        if include_index_etf and t in index_etfs:
            return True
        
        # ETF í¬í•¨ ì—¬ë¶€ì— ë”°ë¼ í•„í„°ë§
        if include_etf:
            # ETFëŠ” í—ˆìš©í•˜ë˜, ë¦¬ì¸ /ìŠ¤íŒ©ì€ ì œì™¸
            bad_kw = ["ìš°", "ë¦¬ì¸ ", "ìŠ¤íŒ©", "SPAC"]
        else:
            # ETFë„ ì œì™¸
            bad_kw = ["ìš°", "ë¦¬ì¸ ", "ìŠ¤íŒ©", "SPAC", "ETF", "ETN"]
        
        return not any(k in n.upper() or k in n for k in bad_kw)
    
    result = [t for t in tickers if ok(t)]

    # í†µê³„ ì¶œë ¥
    etf_count = sum(1 for t in result if t in index_etfs or "ETF" in names.get(t, "").upper() or "KODEX" in names.get(t, "") or "TIGER" in names.get(t, ""))
    print(f"[INFO] Universe: {len(result)} ì¢…ëª© ({len(tickers)} â†’ í•„í„°ë§, ETF: {etf_count}ê°œ)")
    
    return result


def load_panel(universe, start, end, max_workers=6, include_market_cap=True):
    """
    ì „ì²´ ì¢…ëª© íŒ¨ë„ ë°ì´í„° ë¡œë“œ
    
    Args:
        universe: ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
        start: ì‹œì‘ì¼
        end: ì¢…ë£Œì¼
        max_workers: ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
        include_market_cap: ì‹œê°€ì´ì•¡ í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸: True)
    """
    import time
    from concurrent.futures import ThreadPoolExecutor, as_completed
    datas = {}
    print(f"[INFO] Loading {len(universe)} tickers (parallel={max_workers}, market_cap={include_market_cap})")
    t0 = time.time()

    def _safe_one(t):
        df = get_ohlcv_one(t, start, end, include_market_cap=include_market_cap)
        # DataFrameì´ ì•„ë‹ˆê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ì œì™¸
        if not isinstance(df, pd.DataFrame) or df.empty:
            return None, None
        # í•„ìˆ˜ ì»¬ëŸ¼ ìµœì¢… ê²€ì¦
        if any(col not in df.columns for col in REQ_COLS):
            return None, None
        return t, df

    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futs = {ex.submit(_safe_one, t): t for t in universe}
        for i, f in enumerate(as_completed(futs), 1):
            t = futs[f]
            try:
                k, df = f.result()
                if k is not None:
                    df["ticker"] = k
                    datas[k] = df
            except Exception as e:
                print(f"[WARN] {t}: load -> {type(e).__name__}: {e}")

            if i % 50 == 0 or i == len(futs):
                print(f"  Progress: {i}/{len(futs)} ({i/len(futs)*100:.1f}%)")

    # ì‹œê°€ì´ì•¡ ìˆ˜ì§‘ í†µê³„
    if include_market_cap and len(datas) > 0:
        cap_count = sum(1 for df in datas.values() if "market_cap" in df.columns)
        print(f"[INFO] Market cap collected: {cap_count}/{len(datas)} tickers ({cap_count/len(datas)*100:.1f}%)")
    elif include_market_cap:
        print(f"[WARN] Market cap requested but no data loaded")

    print(f"[INFO] Loaded {len(datas)} tickers in {time.time()-t0:.1f}s")
    return datas
