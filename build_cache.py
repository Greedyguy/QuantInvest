"""
build_cache.py
--------------------------------
ì „ì²´ ì½”ìŠ¤í”¼+ì½”ìŠ¤ë‹¥ ì£¼ì‹ì˜ ì¼ë³„ OHLCV ë°ì´í„°ë¥¼
/data/ohlcv/*.parquet í˜•íƒœë¡œ ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ & ìºì‹œ êµ¬ì¶•

ì²˜ìŒ ì‹¤í–‰ ì‹œ 2~3ë¶„, ì´í›„ 10ì´ˆ ë‚´ ì™„ë£Œ.
"""

import os
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from pykrx import stock
from datetime import date
from data_loader import get_ohlcv_one, get_universe, DATA_DIR
import sys

# ë‹¤ìš´ë¡œë“œ ê¸°ê°„: ìµœê·¼ 5ë…„
START = "2020-01-01"
END = date.today().strftime("%Y-%m-%d")
MAX_WORKERS = 16  # ì‹œìŠ¤í…œì— ë§ê²Œ ì¡°ì • (ë§¥ë¶ M1ì€ 8~12 ì •ë„)

os.makedirs(DATA_DIR, exist_ok=True)
MARKETS = ("KOSPI","KOSDAQ")
if len(sys.argv) > 1:
    m = sys.argv[1].upper()
    if m in ("KOSPI","KOSDAQ"):
        MARKETS = (m,)

def build_all_cache():
    tickers = get_universe(MARKETS)
    existing = {f.split(".")[0] for f in os.listdir(DATA_DIR) if f.endswith(".parquet")}
    to_download = [t for t in tickers if t not in existing]

    print(f"âœ… ì „ì²´ ìœ ë‹ˆë²„ìŠ¤: {len(tickers)}ê°œ ì¢…ëª©")
    print(f"ğŸ“¦ ì´ë¯¸ ìºì‹œëœ ì¢…ëª©: {len(existing)}ê°œ")
    print(f"â¬‡ï¸ ìƒˆë¡œ ë‹¤ìš´ë¡œë“œí•  ì¢…ëª©: {len(to_download)}ê°œ")
    if not to_download:
        print("ëª¨ë“  ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤!")
        return

    start_t = time.time()
    success, fail = [], []

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        futures = {ex.submit(get_ohlcv_one, t, START, END): t for t in to_download}
        for i, f in enumerate(as_completed(futures), 1):
            t = futures[f]
            df = f.result()
            if not df.empty:
                success.append(t)
            else:
                fail.append(t)

            if i % 100 == 0 or i == len(futures):
                pct = 100 * i / len(futures)
                print(f"  ì§„í–‰ë¥ : {i}/{len(futures)} ({pct:.1f}%)")

    elapsed = time.time() - start_t
    print(f"ğŸ ì™„ë£Œ: ì„±ê³µ {len(success)}ê°œ, ì‹¤íŒ¨ {len(fail)}ê°œ, ì†Œìš” {elapsed/60:.1f}ë¶„")

    summary = pd.DataFrame({
        "success": [len(success)],
        "fail": [len(fail)],
        "elapsed_min": [elapsed / 60]
    })
    pd.DataFrame({"success_tickers": success}).to_csv("cache_success.csv", index=False)
    pd.DataFrame({"fail_tickers": fail}).to_csv("cache_fail.csv", index=False)
    summary.to_csv("cache_summary.csv", index=False)

if __name__ == "__main__":
    build_all_cache()